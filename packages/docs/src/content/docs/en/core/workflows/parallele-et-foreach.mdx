---
title: Parallel & forEach
description: Map your data with concurrency control and parallel steps
sidebar:
  order: 3
locale: en-US
---

`createParallelStep` and `createForEachStep` let you run several substeps concurrently. Use them to process large collections or aggregate analytical tasks.

## Chunking pipeline

The example below splits a text and applies parallel processing to each chunk.

```ts
import {
  Chunk,
  TChunkDocument,
  createForEachStep,
  createParallelStep,
  createStep,
  createWorkflow,
} from "@ai_kit/core";
import { z } from "zod";

const chunkText = createStep<{ text: string }, Chunk[]>({
  id: "chunk-text",
  description: "Split the source text into homogeneous segments",
  handler: async ({ input }) => {
    const document = TChunkDocument.fromText(input.text);
    return document.chunk({
      chunkSize: 200,
      chunkOverlap: 20,
      metadata: { source: "raw-text" },
    });
  },
});

const embedChunk = createStep<Chunk, number[]>({
  id: "embed-chunk",
  description: "Compute an embedding for a chunk",
  handler: async ({ input }) => {
    // Replace with your embedding model; using a deterministic stub here
    return Array.from({ length: 3 }, (_, i) => input.content.length * (i + 1));
  },
});

const tagChunk = createStep<Chunk, string[]>({
  id: "tag-chunk",
  description: "Extract key tags from the chunk",
  handler: async ({ input }) => {
    return input.content
      .split(/[^a-zA-ZÀ-ÿ]+/)
      .filter((word) => word.length > 4)
      .slice(0, 5);
  },
});

const processChunk = createParallelStep({
  id: "process-chunk",
  description: "Run analytical tasks in parallel for a chunk",
  steps: {
    embedding: embedChunk,
    tags: tagChunk,
  },
});

const foreachChunk = createForEachStep({
  id: "foreach-chunk",
  description: "Process each chunk by reusing the parallel step",
  items: ({ input }) => input,
  itemStep: processChunk,
  concurrency: 4,
});

export const chunkingWorkflow = createWorkflow({
  id: "chunking-parallel-pipeline",
  description: "Chunking + parallel processing for each segment",
  inputSchema: z.object({ text: z.string().min(1) }),
  outputSchema: z.array(
    z.object({
      embedding: z.array(z.number()),
      tags: z.array(z.string()),
    }),
  ),
})
  .then(chunkText)
  .then(foreachChunk)
  .commit();
```

`createForEachStep` returns an array by default: use the `collect` option to merge results (e.g. concatenate embeddings). `TChunkDocument` ensures consistent chunking and metadata propagation (`source: "raw-text"`).

## Controlled concurrency

- The `concurrency` parameter of `createForEachStep` limits how many items run in parallel (1 by default). Increase it when your handlers are I/O-bound.
- Steps declared in `createParallelStep` execute simultaneously and their outputs are grouped into an object.
- Combine parallel and foreach to optimize pipelines without sacrificing readability.

## Parallel branches in workflow builders

When you compose workflows with `createWorkflow`, prefer the fluent `.branchParallel()` helper instead of wiring `createParallelStep` manually. It lets you describe full branch sequences, reuse existing steps, and configure error handling or aggregation in one place.

```ts
import { createStep, createWorkflow } from "@ai_kit/core";

const provisionInfra = createStep({
  id: "provision-infra",
  handler: async ({ input }) => ({ clusterId: `cluster-${input}` }),
});

const bootstrapObservability = createStep({
  id: "bootstrap-observability",
  handler: async ({ input }) => ({ dashboardUrl: `https://dash/${input}` }),
});

export const setupWorkflow = createWorkflow({ id: "setup" })
  .branchParallel("prepare-environment", parallel =>
    parallel
      .branch("infra", branch => branch.then(provisionInfra))
      .branch("observability", branch => branch.then(bootstrapObservability))
      .onError("wait-all")
      .aggregate(({ results }) => ({
        cluster: results.infra.clusterId,
        dashboard: results.observability.dashboardUrl,
      })),
  )
  .commit();
```

- Branches receive the current input and can run any step sequence (`then`, `while`, `conditions`, …). Attempting to nest another `branchParallel` currently throws a `WorkflowSchemaError`.
- The workflow context (`ctx`) is read-only inside branches; calling `stepRuntime.updateCtx()` results in a `WorkflowExecutionError`.
- Error strategy defaults to **fail-fast**; switch to `"wait-all"` to collect every failure before rejecting. Aggregation defaults to the raw `{ [branchName]: output }` map—override it with `.aggregate()` to transform or combine branch outputs.

## Observability

Each branch execution emits the usual `step:*` events with extra metadata (`parallelGroupId`, `parallelBranchId`). Tap into `run.watch()` to follow branch lifecycles and inspect durations.

Want to conditionally control execution instead? Check [`Conditional branches`](./branches-conditionnelles). To repeat a step until a predicate is satisfied, visit the [`While loops`](./boucles-while) page.
