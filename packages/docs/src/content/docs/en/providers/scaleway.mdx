---
title: Scaleway
description: Use the Scaleway provider with AI Kit
sidebar:
  order: 1
locale: en-US
---

import { PackageManagers } from 'starlight-package-managers'

The Scaleway provider lets you run the LLM models hosted on the [Scaleway AI](https://www.scaleway.com/ai/) platform with AI Kit. It relies on Scaleway's OpenAI-compatible API.

## Installation

Install the required dependencies:

<PackageManagers pkg="@ai_kit/core @ai-sdk/openai ai" />

## Configuration

Configure your Scaleway API key in an environment variable:

```bash
export SCALEWAY_API_KEY="skw-..."
```

You can obtain your API key from the [Scaleway console](https://console.scaleway.com/iam/api-keys).

## Use with an Agent

Import the `scaleway` provider and use it to create an agent:

```ts
import { Agent, scaleway } from "@ai_kit/core";

const assistant = new Agent({
  name: "assistant-scaleway",
  instructions: "You are a helpful and accurate assistant.",
  model: scaleway("gpt-oss-120b"),
});

const result = await assistant.generate({
  prompt: "What is the capital city of France?",
});

console.log(result.text);
```

## Available models

Scaleway exposes several LLMs through the provider:

| Model | Description | Size |
|--------|-------------|--------|
| `gpt-oss-120b` | High-performance general model | 120B |
| `llama-3.3-70b-instruct` | Meta Llama 3.3 optimized for instructions | 70B |
| `llama-3.1-8b-instruct` | Compact Meta Llama 3.1 | 8B |
| `mistral-small-3.2-24b-instruct-2506` | Latest Mistral Small generation | 24B |
| `mistral-nemo-instruct-2407` | Optimized Mistral Nemo | 12B |
| `qwen3-235b-a22b-instruct-2507` | Large-capacity Qwen 3 | 235B |
| `qwen3-coder-30b-a3b-instruct` | Qwen 3 specialized for code | 30B |
| `deepseek-r1-distill-llama-70b` | Distilled DeepSeek R1 | 70B |
| `gemma-3-27b-it` | Google Gemma 3 | 27B |
| `voxtral-small-24b-2507` | Voxtral Small | 24B |
| `devstral-small-2505` | Devstral Small for development | 25B |
| `pixtral-12b-2409` | Pixtral multimodal | 12B |

## Usage examples

### Generate structured output

```ts
import { Agent, scaleway, Output } from "@ai_kit/core";
import { z } from "zod";

const codeSchema = Output.object({
  schema: z.object({
    language: z.string(),
    code: z.string(),
    explanation: z.string(),
  }),
});

const assistant = new Agent({
  name: "code-assistant",
  instructions: "You are a programming expert.",
  model: scaleway("qwen3-coder-30b-a3b-instruct"),
});

const result = await assistant.generate({
  prompt: "Write a Python function that computes the Fibonacci sequence.",
  structuredOutput: codeSchema,
});

console.log(result.experimental_output);
```

### Use inside a workflow

```ts
import { Agent, createStep, createWorkflow, scaleway } from "@ai_kit/core";
import { z } from "zod";

const assistant = new Agent({
  name: "analyzer",
  instructions: "Analyze the sentiment of the text.",
  model: scaleway("mistral-small-3.2-24b-instruct-2506"),
});

const analyzeStep = createStep({
  id: "analyze-text",
  inputSchema: z.object({ text: z.string() }),
  handler: async ({ input }) => {
    const result = await assistant.generate({
      prompt: `Analyze the sentiment of this text: "${input.text}"`,
    });

    return { sentiment: result.text };
  },
});

const workflow = createWorkflow({
  id: "sentiment-analysis",
  inputSchema: z.object({ text: z.string() }),
  outputSchema: z.object({ sentiment: z.string() }),
})
  .then(analyzeStep)
  .commit();
```

### Stream responses

```ts
const assistant = new Agent({
  name: "assistant-stream",
  instructions: "You are a creative assistant.",
  model: scaleway("llama-3.3-70b-instruct"),
});

const stream = await assistant.stream({
  prompt: "Tell me a short story about a robot learning how to cook.",
  temperature: 0.7,
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

## Choosing the right model

- **For code generation:** `qwen3-coder-30b-a3b-instruct`, `devstral-small-2505`
- **For general-purpose tasks:** `gpt-oss-120b`, `llama-3.3-70b-instruct`
- **For lightweight applications:** `llama-3.1-8b-instruct`, `mistral-nemo-instruct-2407`
- **For complex reasoning:** `deepseek-r1-distill-llama-70b`, `qwen3-235b-a22b-instruct-2507`
- **For multimodal work:** `pixtral-12b-2409`

## Best practices

1. **Manage API keys:** never commit your API key. Use environment variables or a secrets manager.
2. **Monitor usage:** Scaleway's billing is model-dependent; track your consumption to avoid surprises.
3. **Handle retries:** transient errors can happen. Wrap calls with retry logic suited to your workload.
