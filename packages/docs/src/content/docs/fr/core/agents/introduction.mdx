---
title: Introduction
description: Installer @ai_kit/core et générer vos premières réponses
sidebar:
  order: 2
locale: fr-FR
---

import { PackageManagers } from 'starlight-package-managers'

## Installation

Installez la bibliothèque core ainsi que le SDK modèle choisi :

<PackageManagers pkg="@ai_kit/core @ai-sdk/openai ai zod" />

## Créer un agent

```ts
import { Agent, scaleway } from "@ai_kit/core";

const assistant = new Agent({
  name: "assistant-documentation",
  instructions: "Tu aides les développeurs à comprendre la plateforme AI Kit.",
  model: scaleway("gpt-oss-120b"),
});
```

- `name` identifie votre agent (journalisation, supervision, métriques).
- `instructions` définit les consignes système appliquées par défaut. Vous pouvez les surcharger via `system` sur chaque appel.
- `model` attend un `LanguageModel` du SDK `ai`. Ici nous utilisons le modèle Scaleway, mais tout modèle compatible fonctionne.

## Générer une réponse ponctuelle

Utilisez `agent.generate` lorsque vous attendez une réponse unique. Vous pouvez fournir un simple `prompt` ou une conversation `messages` compatible ChatML.

```ts
const result = await assistant.generate({
  prompt: "Explique la différence entre generate et stream dans AI Kit."
});

console.log(result.text);
```

L'objet renvoyé par `generate` correspond à `ai.generateText` :

- `text` contient la réponse finale.
- `response` expose les métadonnées brutes (messages, usage, tool calls...).
- `loopTool` vaut `true` si la boucle d'outils a été déclenchée.

### Utiliser des messages structurés

```ts
const chatResult = await assistant.generate({
  messages: [
    { role: "user", content: "Peux-tu me donner trois idées de tutoriels ?" }
  ],
  maxOutputTokens: 256
});
```

Lorsque vous passez `messages`, l'agent injecte automatiquement `instructions` comme système, sauf si vous fournissez explicitement `system`.
